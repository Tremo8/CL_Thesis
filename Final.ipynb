{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwj4CkTzzcWr"
      },
      "source": [
        "# CL Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPXJaZZjzcWu"
      },
      "source": [
        "## Installation\n",
        "Install all the necessary library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzF55R6dzcWv",
        "outputId": "d65bed89-f433-46e7-b780-98c68180e51c"
      },
      "outputs": [],
      "source": [
        "! pip install avalanche-lib==0.3.1\n",
        "! pip install micromind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E3yHNRPzcWw",
        "outputId": "b9bbc510-11f7-4381-d4dc-5cfb5c67f2a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\matte\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x24a0a5b9f90>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD, Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from avalanche.benchmarks.classic import SplitMNIST, SplitCIFAR10\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.training.storage_policy import ReservoirSamplingBuffer\n",
        "\n",
        "\n",
        "from strategy.joint_training import JointTraining\n",
        "from strategy.fine_tuning import FineTuning\n",
        "from strategy.comulative import Comulative\n",
        "from strategy.replay import Replay\n",
        "from strategy.latent_replay import LatentReplay\n",
        "from model.phinet_v2 import PhiNet_v2\n",
        "from model.phinet_v3 import PhiNetV3\n",
        "import utils\n",
        "import evaluations\n",
        "\n",
        "from micromind import PhiNet\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KDShngxzcWy"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i52l8jKzcWy",
        "outputId": "668663c0-52d7-4877-a8d0-d8de1fc5a070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "split_mnist = SplitMNIST(n_experiences=5, seed=0, return_task_id = True)\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Resize((160, 160)),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "split_cifar = SplitCIFAR10(n_experiences=5, seed=0, return_task_id = True, train_transform = transform, eval_transform = transform)\n",
        "\n",
        "# recovering the train and test streams\n",
        "train_stream = split_mnist.train_stream\n",
        "test_stream = split_mnist.test_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5L7IPziq65jv",
        "outputId": "4ab47d92-b0b1-4db2-af44-67e2ed3a6a07"
      },
      "outputs": [],
      "source": [
        "# Function to display images\n",
        "def show_images(images, labels, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        img = np.transpose(images[i].numpy(), (1, 2, 0))\n",
        "        label = labels[i]\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Label: {label}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_images_to_show = 5\n",
        "for exp in train_stream:\n",
        "    indices = np.random.randint(0, len(exp.dataset), num_images_to_show)\n",
        "    images = [exp.dataset[i][0] for i in indices]\n",
        "    labels = [class_names[exp.dataset[i][1]] for i in indices]\n",
        "    print(images[0].shape)\n",
        "    # Show the images\n",
        "    show_images(images, labels, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GApUVD8lzcWz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwiSC9dzcW0"
      },
      "source": [
        "### Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AvfBVXfazcW1"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define other necessary parameters\n",
        "train_mb_size = 128\n",
        "eval_mb_size = 128\n",
        "\n",
        "accs = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWJxGNh9zcW2"
      },
      "source": [
        "### Fine Tuning Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "vJFWY3eVzcW2",
        "outputId": "4b52800b-279b-4dfd-bd63-31ec216d6370"
      },
      "outputs": [],
      "source": [
        "model1 = PhiNet(input_shape = (1, 28, 28), alpha = 0.5, beta = 1, t_zero = 6,num_layers=7 ,include_top = True, num_classes = 10).to(device)\n",
        "#model1 = PhiNet.from_pretrained(\"CIFAR-10\", 3.0, 0.75, 6.0, 7, 160, classifier=True).to(device)\n",
        "optimizer1 = Adam(model1.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "train_epochs = 4\n",
        "\n",
        "fine_tuning = FineTuning(\n",
        "    model=model1,\n",
        "    optimizer=optimizer1,\n",
        "    criterion=criterion,\n",
        "    train_mb_size=train_mb_size,\n",
        "    train_epochs=train_epochs,\n",
        "    eval_mb_size=eval_mb_size,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "fine_tuning.train(train_stream, test_stream, plotting=True)\n",
        "b,c = fine_tuning.test(test_stream)\n",
        "a = fine_tuning.get_tasks_acc()\n",
        "accs['Fine Tuning'] = a\n",
        "print(f\"a: {a}, b: {b}, c: {c}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-tRVDugzcW3"
      },
      "source": [
        "### Joint Training Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsNBEspqzcW4"
      },
      "outputs": [],
      "source": [
        "model2 = PhiNet(input_shape = (1, 28, 28), alpha = 0.5, beta = 1, t_zero = 6,num_layers=7 ,include_top = True, num_classes = 10).to(device)\n",
        "#model2 = PhiNet.from_pretrained(\"CIFAR-10\", 3.0, 0.75, 6.0, 7, 160, classifier=True).to(device)\n",
        "optimizer2 = Adam(model2.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "train_epochs = 4\n",
        "\n",
        "joint_training = JointTraining(\n",
        "    model=model2,\n",
        "    optimizer=optimizer2,\n",
        "    criterion=criterion,\n",
        "    train_mb_size=train_mb_size,\n",
        "    train_epochs=train_epochs,\n",
        "    eval_mb_size=eval_mb_size,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "joint_training.train(train_stream, test_stream, plotting=True)\n",
        "b,c = joint_training.test(test_stream)\n",
        "a = joint_training.get_tasks_acc()\n",
        "\n",
        "print(f\"a: {a}, b: {b}, c: {c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggTVXamGzcW4"
      },
      "source": [
        "### Comulative Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2HgeprNzcW5"
      },
      "outputs": [],
      "source": [
        "model3 = PhiNet(input_shape = (1, 28, 28), alpha = 0.5, beta = 1, t_zero = 6,num_layers=7 ,include_top = True, num_classes = 10).to(device)\n",
        "#model3 = PhiNet.from_pretrained(\"CIFAR-10\", 3.0, 0.75, 6.0, 7, 160, classifier=True).to(device)\n",
        "\n",
        "optimizer3 = Adam(model3.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "train_epochs = 4\n",
        "\n",
        "comulative = Comulative(\n",
        "    model=model3,\n",
        "    optimizer=optimizer3,\n",
        "    criterion=criterion,\n",
        "    train_mb_size=train_mb_size,\n",
        "    train_epochs=train_epochs,\n",
        "    eval_mb_size=eval_mb_size,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "comulative.train(train_stream, test_stream, plotting=True)\n",
        "b,c = comulative.test(test_stream)\n",
        "a = comulative.get_tasks_acc()\n",
        "accs['Comulative'] = a\n",
        "print(f\"a: {a}, b: {b}, c: {c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tS1PK2uzcW6"
      },
      "source": [
        "### Replay Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE0_3a8DzcW6"
      },
      "outputs": [],
      "source": [
        "model4 = PhiNet(input_shape = (1, 28, 28), alpha = 0.5, beta = 1, t_zero = 6,num_layers=7 ,include_top = True, num_classes = 10).to(device)\n",
        "#model4 = PhiNet.from_pretrained(\"CIFAR-10\", 3.0, 0.75, 6.0, 7, 160, classifier=True).to(device)\n",
        "\n",
        "optimizer4 = Adam(model4.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "storage_p = ReservoirSamplingBuffer(max_size=1500)\n",
        "\n",
        "train_epochs = 4\n",
        "\n",
        "replay = Replay(\n",
        "    model=model4,\n",
        "    optimizer=optimizer4,\n",
        "    criterion=criterion,\n",
        "    train_mb_size=train_mb_size,\n",
        "    train_epochs=train_epochs,\n",
        "    eval_mb_size=eval_mb_size,\n",
        "    storage_policy = storage_p,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "replay.train(train_stream, test_stream, plotting=True)\n",
        "b,c = replay.test(test_stream)\n",
        "a = replay.get_tasks_acc()\n",
        "accs['ExpReplay'] = a\n",
        "print(f\"a: {a}, b: {b}, c: {c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ7gVY7H9moR"
      },
      "source": [
        "### Latent Replay Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qextF3Z99moR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start of the training process...\n",
            "Training of the experience with class:  [1, 4]\n",
            "Epoch: 1/1, Train Loss: 5.8908, Train Accuracy: 96.07%\n",
            "\n",
            "Test after the training of the experience with class:  [1, 4]\n",
            "Starting the testing...\n",
            "Testing task  0\n",
            "Classes in this task: [1, 4]\n",
            "Test Loss: 0.0307, Test Accuracy: 99.24%\n",
            "Testing task  1\n",
            "Classes in this task: [5, 7]\n",
            "Test Loss: 9.4277, Test Accuracy: 0.00%\n",
            "Testing task  2\n",
            "Classes in this task: [9, 3]\n",
            "Test Loss: 9.5017, Test Accuracy: 0.00%\n",
            "Testing task  3\n",
            "Classes in this task: [0, 8]\n",
            "Test Loss: 8.2820, Test Accuracy: 0.00%\n",
            "Testing task  4\n",
            "Classes in this task: [2, 6]\n",
            "Test Loss: 8.6703, Test Accuracy: 0.00%\n",
            "Average accuracy: 19.85%\n",
            "Average accuracy of the encutered tasks: 99.24\n",
            "-----------------------------------------------------------------------------------\n",
            "Training of the experience with class:  [5, 7]\n",
            "Epoch: 1/1, Train Loss: 5.2488, Train Accuracy: 94.87%\n",
            "\n",
            "Test after the training of the experience with class:  [5, 7]\n",
            "Starting the testing...\n",
            "Testing task  0\n",
            "Classes in this task: [1, 4]\n",
            "Test Loss: 0.0285, Test Accuracy: 99.15%\n",
            "Testing task  1\n",
            "Classes in this task: [5, 7]\n",
            "Test Loss: 0.1692, Test Accuracy: 94.06%\n",
            "Testing task  2\n",
            "Classes in this task: [9, 3]\n",
            "Test Loss: 8.9111, Test Accuracy: 0.00%\n",
            "Testing task  3\n",
            "Classes in this task: [0, 8]\n",
            "Test Loss: 8.0725, Test Accuracy: 0.00%\n",
            "Testing task  4\n",
            "Classes in this task: [2, 6]\n",
            "Test Loss: 9.6000, Test Accuracy: 0.00%\n",
            "Average accuracy: 38.64%\n",
            "Average accuracy of the encutered tasks: 96.61\n",
            "-----------------------------------------------------------------------------------\n",
            "Training of the experience with class:  [9, 3]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 23\u001b[0m\n\u001b[0;32m      8\u001b[0m train_epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     10\u001b[0m latent_replay \u001b[39m=\u001b[39m LatentReplay(\n\u001b[0;32m     11\u001b[0m     model \u001b[39m=\u001b[39m model4,\n\u001b[0;32m     12\u001b[0m     optimizer \u001b[39m=\u001b[39m optimizer4,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     device \u001b[39m=\u001b[39m device\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m latent_replay\u001b[39m.\u001b[39;49mtrain(train_stream, test_stream, plotting\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     24\u001b[0m b,c \u001b[39m=\u001b[39m latent_replay\u001b[39m.\u001b[39mtest(test_stream)\n\u001b[0;32m     25\u001b[0m a \u001b[39m=\u001b[39m latent_replay\u001b[39m.\u001b[39mget_tasks_acc()\n",
            "File \u001b[1;32mc:\\Users\\matte\\OneDrive - Università degli Studi di Padova\\Control System Engineering\\Thesis\\Test Avalanche\\Project\\strategy\\latent_replay.py:125\u001b[0m, in \u001b[0;36mLatentReplay.train\u001b[1;34m(self, dataset, test_data, plotting)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39m# Data loader initialization\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Called at the start of each learning experience\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m#train_loader = self.make_train_dataloader(exp.dataset, shuffle=True)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m# Training loop over the current experience\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_epochs):\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_epoch(train_loader)\n\u001b[0;32m    126\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Accuracy: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39macc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[39m# Update the memory\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\matte\\OneDrive - Università degli Studi di Padova\\Control System Engineering\\Thesis\\Test Avalanche\\Project\\strategy\\latent_replay.py:212\u001b[0m, in \u001b[0;36mLatentReplay.training_epoch\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    208\u001b[0m     lat_mb_x \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Forward pass. Here we are injecting latent patterns lat_mb_x.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39m# lat_mb_x will be None for the very first batch (batch 0)\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmb_output, lat_acts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmbatch[\u001b[39m0\u001b[39;49m], latent_input\u001b[39m=\u001b[39;49mlat_mb_x, return_lat_acts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# On the first epoch only: store latent activations. Those\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# activations will be used to update the replay buffer.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     lat_acts \u001b[39m=\u001b[39m lat_acts\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mcpu()\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\matte\\OneDrive - Università degli Studi di Padova\\Control System Engineering\\Thesis\\Test Avalanche\\Project\\model\\phinet_v3.py:84\u001b[0m, in \u001b[0;36mPhiNetV3.forward\u001b[1;34m(self, x, latent_input, return_lat_acts)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m latent_input \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 84\u001b[0m         orig_acts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlat_features(orig_acts)\n\u001b[0;32m     85\u001b[0m     lat_acts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((orig_acts, latent_input), \u001b[39m0\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\micromind\\networks\\phinet.py:405\u001b[0m, in \u001b[0;36mPhiNetConvBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    402\u001b[0m     inp \u001b[39m=\u001b[39m x\n\u001b[0;32m    404\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layers:\n\u001b[1;32m--> 405\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_conn:\n\u001b[0;32m    408\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m inp\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\avalanche\\models\\batch_renorm.py:132\u001b[0m, in \u001b[0;36mBatchRenorm2D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     x \u001b[39m=\u001b[39m (x \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_avg_mean) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_avg_std\n\u001b[1;32m--> 132\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgamma \u001b[39m*\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta\n\u001b[0;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1598\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_backward_pre_hooks\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1599\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39m=\u001b[39m OrderedDict()\n\u001b[1;32m-> 1601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1602\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1603\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#model4 = PhiNet.from_pretrained(\"CIFAR-10\", 3.0, 0.75, 6.0, 7, 160, classifier=False).to(device)\n",
        "model4 = PhiNet(input_shape = (1, 28, 28), alpha = 0.5, beta = 1, t_zero = 6,num_layers=7 ,include_top = False, num_classes = 10).to(device)\n",
        "model4.load_state_dict(torch.load(\"TestModel/7_Layers/Adam.pth\", map_location=torch.device(device)))\n",
        "\n",
        "model4 = PhiNetV3(model4, latent_layer_num = 9, replace_bn_with_brn = True).to(device)\n",
        "optimizer4 = Adam(model4.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "train_epochs = 1\n",
        "\n",
        "latent_replay = LatentReplay(\n",
        "    model = model4,\n",
        "    optimizer = optimizer4,\n",
        "    criterion = criterion,\n",
        "    train_mb_size = 21,\n",
        "    replay_mb_size = 107,\n",
        "    train_epochs = train_epochs,\n",
        "    eval_mb_size = eval_mb_size,\n",
        "    rm_size = 1500,\n",
        "    manual_mb = True,\n",
        "    device = device\n",
        ")\n",
        "\n",
        "latent_replay.train(train_stream, test_stream, plotting=True)\n",
        "b,c = latent_replay.test(test_stream)\n",
        "a = latent_replay.get_tasks_acc()\n",
        "accs['LatentReplay'] = a\n",
        "\n",
        "mac = evaluations.get_MAC(model4, (1,28,28))\n",
        "print(f\"MAC: {mac}\")\n",
        "\n",
        "mean, std = evaluations.measure_inference_time(model4, (1,28,28))\n",
        "print(f\"Average inference time: {mean:.3f} +/- {std:.3f} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MxjpyeI65j1"
      },
      "outputs": [],
      "source": [
        "utils.plot_accs(accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotter = utils.TaskAccuracyPlotter()\n",
        "\n",
        "for key, value in accs.items():\n",
        "    print(f\"Strategy: {key}, Tasks: {list(value.keys())}\")\n",
        "    print(f\"Task Accuracy: {value}\")\n",
        "    _ = plotter.plot_task_accuracy(value, label=key, plot_task_acc=True, plot_avg_acc=True, plot_encountered_avg=True)\n",
        "\n",
        "plotter.show_figures()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
