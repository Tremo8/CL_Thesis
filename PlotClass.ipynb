{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class TaskAccuracyPlotter:\n",
    "    def __init__(self):\n",
    "        self.fig1 = None\n",
    "        self.fig2 = None\n",
    "        self.fig3 = None\n",
    "        self.label = None\n",
    "\n",
    "    def plot_individual_task_accuracy(self, task_acc):\n",
    "        \"\"\"\n",
    "        Plot the accuracy of each individual task.\n",
    "\n",
    "        Args:\n",
    "            task_acc (dict): A dictionary containing the accuracy of each task.\n",
    "            label (str, optional): Label for the current plot.\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The updated figure containing the plots.\n",
    "        \"\"\"\n",
    "        if self.fig1 is None:\n",
    "            num_tasks = len(task_acc)\n",
    "            num_rows = (num_tasks + 1) // 2  # Number of rows in the subplots grid\n",
    "            self.fig1, axes = plt.subplots(num_rows, 2, figsize=(15, 5 * num_rows))\n",
    "            axes = axes.flatten()\n",
    "            plot_num = 0\n",
    "        else:\n",
    "            axes = self.fig1.get_axes()\n",
    "            plot_num = 0\n",
    "\n",
    "        for idx, (key, ax) in enumerate(zip(task_acc.keys(), axes[plot_num:])):\n",
    "            ax.plot(task_acc[key], label=self.label, marker='.')\n",
    "            ax.grid(True)\n",
    "            ax.set_xlabel('Task')\n",
    "            ax.set_ylabel('Accuracy')\n",
    "            ax.set_yticks(np.arange(0, 101, 5))\n",
    "            ax.set_ylim(-1, 101)  # Set y-axis limits\n",
    "            ax.set_title(f\"Task {key}\", loc='center')\n",
    "            ax.set_xticks(list(task_acc.keys()))\n",
    "            ax.legend()\n",
    "            plot_num += 1\n",
    "\n",
    "        # Remove any unused subplots if num_tasks is odd\n",
    "        for i in range(plot_num, len(axes)):\n",
    "            self.fig1.delaxes(axes[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return self.fig1\n",
    "\n",
    "    def plot_average_accuracy(self, task_acc):\n",
    "        \"\"\"\n",
    "        Plot the average accuracy of all tasks.\n",
    "\n",
    "        Args:\n",
    "            task_acc (dict): A dictionary containing the accuracy of each task.\n",
    "            label (str, optional): Label for the current plot.\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The figure containing the plot.\n",
    "        \"\"\"\n",
    "        if self.fig2 is None:\n",
    "            self.fig2, ax = plt.subplots(figsize=(10, 6))\n",
    "        else:\n",
    "            ax = self.fig2.get_axes()[0]\n",
    "\n",
    "        num_tasks = len(task_acc)\n",
    "        averages = [sum(values) / num_tasks for values in zip(*task_acc.values())]\n",
    "        ax.plot(averages, marker='.', label=self.label)\n",
    "        ax.grid(True)\n",
    "        ax.set_xlabel('Task')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_yticks(np.arange(0, 101, 5))\n",
    "        ax.set_ylim(-1, 101)\n",
    "        ax.set_xticks(list(task_acc.keys()))\n",
    "        ax.set_title('Average Accuracy')\n",
    "        ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return self.fig2\n",
    "\n",
    "    def plot_encountered_tasks_accuracy(self, task_acc):\n",
    "        \"\"\"\n",
    "        Plot the average accuracy of only encountered tasks.\n",
    "\n",
    "        Args:\n",
    "            task_acc (dict): A dictionary containing the accuracy of each task.\n",
    "            label (str, optional): Label for the current plot.\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The figure containing the plot.\n",
    "        \"\"\"\n",
    "        if self.fig3 is None:\n",
    "            self.fig3, ax = plt.subplots(figsize=(10, 6))\n",
    "        else:\n",
    "            ax = self.fig3.get_axes()[0]\n",
    "\n",
    "        encountered_averages = []\n",
    "        for last_key in range(len(next(iter(task_acc.values())))):\n",
    "            total_last_element = 0\n",
    "            num_keys = 0\n",
    "\n",
    "            for key, value in task_acc.items():\n",
    "                if int(key) <= int(last_key):\n",
    "                    last_element = value[int(last_key)]\n",
    "                    total_last_element += last_element\n",
    "                    num_keys += 1\n",
    "\n",
    "            avg = total_last_element / num_keys\n",
    "            encountered_averages.append(avg)\n",
    "\n",
    "        ax.plot(encountered_averages, marker='.', label=self.label)\n",
    "        ax.grid(True)\n",
    "        ax.set_xlabel('Task')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_yticks(np.arange(0, 101, 5))\n",
    "        ax.set_ylim(-1, 101)\n",
    "        ax.set_xticks(list(task_acc.keys()))\n",
    "        ax.set_title('Average Accuracy of Encountered Tasks')\n",
    "        ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return self.fig3\n",
    "\n",
    "\n",
    "    def show_figures(self):\n",
    "        \"\"\"\n",
    "        Show all figures.\n",
    "        \"\"\"\n",
    "        if self.fig1 is not None:\n",
    "            self.fig1.show()\n",
    "        if self.fig2 is not None:\n",
    "            self.fig2.show()\n",
    "        if self.fig3 is not None:\n",
    "            self.fig3.show()\n",
    "        \n",
    "    def plot_task_accuracy(self, task_acc,  label=None, plot_task_acc=True, plot_avg_acc=True, plot_encountered_avg=True):\n",
    "        \"\"\"\n",
    "        Plot the accuracy of each task, the average accuracy of all tasks, and the average accuracy of only encountered tasks.\n",
    "\n",
    "        Args:\n",
    "            task_acc (dict): A dictionary containing the accuracy of each task.\n",
    "            plot_task_acc (bool): Whether to plot individual task accuracies. Default is True.\n",
    "            plot_avg_acc (bool): Whether to plot average accuracy of all tasks. Default is True.\n",
    "            plot_encountered_avg (bool): Whether to plot average accuracy of only encountered tasks. Default is True.\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        \n",
    "        if plot_task_acc:\n",
    "            fig1 = self.plot_individual_task_accuracy(task_acc)\n",
    "        if plot_avg_acc:\n",
    "            fig2 = self.plot_average_accuracy(task_acc)\n",
    "        if plot_encountered_avg:\n",
    "            fig3 = self.plot_encountered_tasks_accuracy(task_acc)\n",
    "\n",
    "        return self.fig1, self.fig2, self.fig3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "strategy_dict = {\n",
    "    \"Strategy 1\": {\n",
    "        0: [85, 90, 92],\n",
    "        1: [0, 80, 85],\n",
    "        2: [0, 0, 90],\n",
    "        # Add more tasks as needed...\n",
    "    },\n",
    "    \"Strategy 2\": {\n",
    "        0: [90, 92, 88],\n",
    "        1: [0, 95, 89],\n",
    "        2: [0, 0, 78],\n",
    "        # Add more tasks as needed...\n",
    "    },\n",
    "    \"Strategy 3\": {\n",
    "        0: [80, 78, 82],\n",
    "        1: [0, 90, 85],\n",
    "        2: [0, 0, 97],\n",
    "        # Add more tasks as needed...\n",
    "    },\n",
    "}\n",
    "plotter = TaskAccuracyPlotter()\n",
    "\n",
    "fig = None\n",
    "for key, value in strategy_dict.items():\n",
    "    print(f\"Strategy: {key}, Tasks: {list(value.keys())}\")\n",
    "    print(f\"Task Accuracy: {value}\")\n",
    "    _ = plotter.plot_task_accuracy(value, label=key, plot_task_acc=False, plot_avg_acc=True, plot_encountered_avg=True)\n",
    "\n",
    "plotter.show_figures()\n",
    "a = {\n",
    "        0: [85, 90, 92],\n",
    "        1: [0, 80, 85],\n",
    "        2: [0, 0, 90],\n",
    "        # Add more tasks as needed...\n",
    "    }\n",
    "a = {\n",
    "        0: [85],\n",
    "        1: [0],\n",
    "        2: [0],\n",
    "        # Add more tasks as needed...\n",
    "    }\n",
    "_ = plotter.plot_task_accuracy(a, plot_task_acc=True, plot_avg_acc=True, plot_encountered_avg=True)\n",
    "plotter.show_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiNetV3(\n",
      "  (lat_features): Sequential(\n",
      "    (0): ZeroPad2d((0, 1, 0, 1))\n",
      "    (1): SeparableConv2d(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): Conv2d(1, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(144, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (3): HSwish()\n",
      "      )\n",
      "    )\n",
      "    (2): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Dropout2d(p=0.05, inplace=False)\n",
      "        (1): DepthwiseConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (2): BatchNorm2d(144, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (3): HSwish()\n",
      "        (4): Conv2d(144, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(72, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(72, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(416, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): ZeroPad2d((1, 1, 1, 1))\n",
      "        (4): Dropout2d(p=0.05, inplace=False)\n",
      "        (5): DepthwiseConv2d(416, 416, kernel_size=(3, 3), stride=(2, 2), groups=416, bias=False)\n",
      "        (6): BatchNorm2d(416, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (7): HSwish()\n",
      "        (8): SEBlock(\n",
      "          (se_conv): Conv2d(416, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(69, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (9): Conv2d(416, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(72, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(72, 401, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(401, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): Dropout2d(p=0.05, inplace=False)\n",
      "        (4): DepthwiseConv2d(401, 401, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=401, bias=False)\n",
      "        (5): BatchNorm2d(401, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (6): HSwish()\n",
      "        (7): SEBlock(\n",
      "          (se_conv): Conv2d(401, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(66, 401, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (8): Conv2d(401, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(72, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(72, 385, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(385, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): ZeroPad2d((1, 1, 1, 1))\n",
      "        (4): Dropout2d(p=0.05, inplace=False)\n",
      "        (5): DepthwiseConv2d(385, 385, kernel_size=(3, 3), stride=(2, 2), groups=385, bias=False)\n",
      "        (6): BatchNorm2d(385, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (7): HSwish()\n",
      "        (8): SEBlock(\n",
      "          (se_conv): Conv2d(385, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(64, 385, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (9): Conv2d(385, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(144, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(144, 740, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(740, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): Dropout2d(p=0.05, inplace=False)\n",
      "        (4): DepthwiseConv2d(740, 740, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=740, bias=False)\n",
      "        (5): BatchNorm2d(740, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (6): HSwish()\n",
      "        (7): SEBlock(\n",
      "          (se_conv): Conv2d(740, 123, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(123, 740, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (8): Conv2d(740, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(144, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(144, 709, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(709, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): ZeroPad2d((1, 1, 1, 1))\n",
      "        (4): Dropout2d(p=0.05, inplace=False)\n",
      "        (5): DepthwiseConv2d(709, 709, kernel_size=(3, 3), stride=(2, 2), groups=709, bias=False)\n",
      "        (6): BatchNorm2d(709, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (7): HSwish()\n",
      "        (8): SEBlock(\n",
      "          (se_conv): Conv2d(709, 118, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(118, 709, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (9): Conv2d(709, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(288, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(288, 1357, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1357, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): Dropout2d(p=0.05, inplace=False)\n",
      "        (4): DepthwiseConv2d(1357, 1357, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1357, bias=False)\n",
      "        (5): BatchNorm2d(1357, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (6): HSwish()\n",
      "        (7): SEBlock(\n",
      "          (se_conv): Conv2d(1357, 226, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(226, 1357, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (8): Conv2d(1357, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(288, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (end_features): Sequential(\n",
      "    (0): PhiNetConvBlock(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Conv2d(288, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1296, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (2): HSwish()\n",
      "        (3): ZeroPad2d((1, 1, 1, 1))\n",
      "        (4): Dropout2d(p=0.05, inplace=False)\n",
      "        (5): DepthwiseConv2d(1296, 1296, kernel_size=(3, 3), stride=(2, 2), groups=1296, bias=False)\n",
      "        (6): BatchNorm2d(1296, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "        (7): HSwish()\n",
      "        (8): SEBlock(\n",
      "          (se_conv): Conv2d(1296, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (se_conv2): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (activation): HSwish()\n",
      "        )\n",
      "        (9): Conv2d(1296, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(576, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=576, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from micromind import PhiNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "from model.phinet_v2 import PhiNet_v2\n",
    "from model.phinet_v3 import PhiNetV3\n",
    "\n",
    "#model = PhiNet_v2(pretrained=\"TestModel/7_Layers/Adam.pth\", num_layers= 7, latent_layer_num=9)\n",
    "model1 = PhiNet(input_shape=(1,28,28), alpha=3, beta=0.75, t_zero=6, num_layers=7, include_top=False)\n",
    "model1 = PhiNetV3(model1, latent_layer_num = 9)\n",
    "\n",
    "print(model1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
